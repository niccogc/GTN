{
  "experiment_name": "abalone",
  "run_name": "MPO2_L4_d4_j5_s7",
  "config": {
    "output_site": 1,
    "init_strength": 0.01,
    "batch_size": 100,
    "n_epochs": 10,
    "jitter_decay": 0.95,
    "jitter_min": 0.001,
    "adaptive_jitter": true,
    "patience": 4,
    "min_delta": 0.001,
    "train_selection": true,
    "rank": 5,
    "seeds": [
      42,
      7,
      123,
      256,
      999
    ],
    "model": "MPO2",
    "L": 4,
    "bond_dim": 4,
    "jitter_start": 5.0,
    "reduction_factor": 0.5
  },
  "hparams": {
    "seed": 7,
    "model": "MPO2",
    "dataset": "abalone",
    "output_site": 1,
    "init_strength": 0.01,
    "batch_size": 100,
    "n_epochs": 10,
    "jitter_decay": 0.95,
    "jitter_min": 0.001,
    "adaptive_jitter": true,
    "patience": 4,
    "min_delta": 0.001,
    "train_selection": true,
    "rank": 5,
    "seeds": [
      42,
      7,
      123,
      256,
      999
    ],
    "L": 4,
    "bond_dim": 4,
    "jitter_start": 5.0,
    "reduction_factor": 0.5
  },
  "metrics_log": [
    {
      "step": -1,
      "train_loss": 17023734.468027946,
      "train_quality": -1623383.4221129091,
      "val_loss": 95254.24726603615,
      "val_quality": -9493.193524971337
    }
  ],
  "summary": {
    "run_id": "MPO2-L4-d4-init0.01-jit5-rf0.5-seed7",
    "seed": 7,
    "model": "MPO2",
    "grid_params": {
      "model": "MPO2",
      "L": 4,
      "bond_dim": 4,
      "jitter_start": 5.0,
      "reduction_factor": 0.5,
      "init_strength": 0.01
    },
    "train_loss": null,
    "train_quality": null,
    "val_loss": null,
    "val_quality": null,
    "test_loss": null,
    "test_quality": null,
    "success": false,
    "error": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasDgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
    "traceback": "Traceback (most recent call last):\n  File \"/zhome/6b/e/212868/GTN/experiments/run_grid_search.py\", line 265, in run_single_experiment\n    scores_train, scores_val = ntn.fit(\n                               ^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 875, in fit\n    self.update_tn_node(\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 754, in update_tn_node\n    delta_tensor = self._get_node_update(\n                   ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 556, in _get_node_update\n    b, H = self._compute_H_b(node_tag)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 178, in _compute_H_b\n    J, H = self.compute_node_derivatives(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 123, in compute_node_derivatives\n    return self._sum_over_batches(\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 96, in _sum_over_batches\n    batch_result = batch_operation(*inputs, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/model/base/NTN.py\", line 156, in _batch_node_derivatives\n    node_grad = grad_tn.contract(output_inds=node_inds)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/quimb/tensor/tensor_core.py\", line 9354, in contract\n    return tensor_contract(\n           ^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/functools.py\", line 912, in wrapper\n    return dispatch(args[0].__class__)(*args, **kw)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/quimb/tensor/tensor_core.py\", line 310, in tensor_contract\n    data_out = array_contract(\n               ^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/quimb/tensor/contraction.py\", line 285, in array_contract\n    return ctg.array_contract(\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/cotengra/interface.py\", line 864, in array_contract\n    return expr(*arrays, backend=backend)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/cotengra/contract.py\", line 784, in __call__\n    p_array = _tensordot(l_array, r_array, arg)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/autoray/autoray.py\", line 2388, in numpy_like\n    return fn(a, b, dims=axes)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/zhome/6b/e/212868/GTN/.venv/lib/python3.12/site-packages/torch/functional.py\", line 1333, in tensordot\n    return _VF.tensordot(a, b, dims_a, dims_b)  # type: ignore[attr-defined]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasDgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n"
  }
}