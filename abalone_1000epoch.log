Loading abalone dataset...
Dataset: 2923 train, 627 val, 627 test
Input dim: 11, Output dim: 1
Creating model: MPO2 with L=2, bond_dim=8
Starting training for 1000 epochs (no early stopping)...
Epoch   1: Train Loss=1354.8492, Val Loss=427.5860, Val R²=-41.6184
Epoch  51: Train Loss=47.0723, Val Loss=43.3621, Val R²=-3.3220
Epoch 101: Train Loss=11.4654, Val Loss=13.1636, Val R²=-0.3120
Epoch 151: Train Loss=7.0115, Val Loss=7.8427, Val R²=0.2183
Epoch 201: Train Loss=5.2497, Val Loss=5.8800, Val R²=0.4139
Epoch 251: Train Loss=4.7499, Val Loss=5.3398, Val R²=0.4678
Epoch 301: Train Loss=4.5783, Val Loss=5.3162, Val R²=0.4701
Epoch 351: Train Loss=4.4731, Val Loss=5.1443, Val R²=0.4873
Epoch 401: Train Loss=4.5418, Val Loss=5.1167, Val R²=0.4900
Epoch 451: Train Loss=4.3665, Val Loss=5.1020, Val R²=0.4915
Epoch 501: Train Loss=4.3567, Val Loss=5.2165, Val R²=0.4801
Epoch 551: Train Loss=4.5111, Val Loss=5.0010, Val R²=0.5015
Epoch 601: Train Loss=4.4556, Val Loss=5.0513, Val R²=0.4965
Epoch 651: Train Loss=4.3094, Val Loss=5.0023, Val R²=0.5014
Epoch 701: Train Loss=4.3091, Val Loss=4.9539, Val R²=0.5062
Epoch 751: Train Loss=4.3316, Val Loss=4.9618, Val R²=0.5054
Epoch 801: Train Loss=4.2807, Val Loss=4.9423, Val R²=0.5074
Epoch 851: Train Loss=4.3002, Val Loss=4.9452, Val R²=0.5071
Epoch 901: Train Loss=4.3429, Val Loss=4.9604, Val R²=0.5056
Epoch 951: Train Loss=4.3410, Val Loss=5.0785, Val R²=0.4938
Epoch 1000: Train Loss=4.3412, Val Loss=4.8721, Val R²=0.5144

Final results:
.4f
.4f
.4f

Plot saved as: test_plots/abalone_gtn_progression_L2_1000epochs.png
