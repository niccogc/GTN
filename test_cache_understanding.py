# Understanding the cache behavior

print("Cache behavior:")
print("- Each batch has unique input tensors")
print("- Cache key = id(inputs[0])")
print("- When we update node 0_Pi for batch 1, we create cache entry for batch 1")
print("- When we update node 0_Pa for SAME batch 1, we REUSE that cache (HIT!)")
print("- When we update node 1_Pi for SAME batch 1, we REUSE that cache (HIT!)")
print("")
print("So within ONE node update:")
print("  - We process 5 batches")
print("  - First batch: MISS (create cache)")
print("  - Remaining 4 batches: each is a new batch, so 4 more MISSES")
print("  - Total: 5 misses, 0 hits")
print("")
print("But if we update MULTIPLE nodes with the SAME batches:")
print("  - Node 0_Pi: 5 misses (create caches for 5 batches)")  
print("  - Node 0_Pa: 5 hits (reuse caches for same 5 batches)")
print("  - Node 1_Pi: 5 hits (reuse caches for same 5 batches)")
print("  - etc.")
print("")
print("This is exactly what we saw: 195 hits, 5 misses for 5 epochs!")
print("That means 5 misses in first pass, then 195 cache hits across all other node updates")
