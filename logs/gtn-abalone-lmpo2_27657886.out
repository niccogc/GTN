
Loading dataset: abalone
  Task: regression
  Train: 2923 samples
  Val: 627 samples
  Test: 627 samples
  Input dim: 11
  Output dim: 1
  Device: cuda
======================================================================
EXPERIMENT PLAN SUMMARY
======================================================================
Total experiments: 810
Grid combinations: 162
Seeds per combination: 5

Parameter Grid:
  model: ['LMPO2', 'LMPO2TypeI_GTN'] (n=2)
  L: [2, 3, 4] (n=3)
  bond_dim: [4, 6, 8] (n=3)
  lr: [0.01, 0.001, 0.0001] (n=3)
  reduction_factor: [0.1, 0.3, 0.5] (n=3)

Fixed Parameters:
  output_site: 1
  batch_size: 32
  n_epochs: 1000
  patience: 40
  min_delta: 1e-08
  optimizer: adamw
  init_strength: 0.01
  rank: 5

Example runs (first 5):
  1. LMPO2-L2-d4-rf0.1-seed42
  2. LMPO2-L2-d4-rf0.1-seed7
  3. LMPO2-L2-d4-rf0.1-seed123
  4. LMPO2-L2-d4-rf0.1-seed256
  5. LMPO2-L2-d4-rf0.1-seed999
  ... (805 more)


[1/810] Running: LMPO2-L2-d4-rf0.1-seed42
  AIM run started: 5c86e0df750243f480d98068
  ✓ SUCCESS: Test R²=0.5911

[2/810] Running: LMPO2-L2-d4-rf0.1-seed7
  AIM run started: e7faa1fcee4748688a02b80a
  ✓ SUCCESS: Test R²=0.5597

[3/810] Running: LMPO2-L2-d4-rf0.1-seed123
  AIM run started: ebd2fe0bca2a4c3287efcb84
  ✓ SUCCESS: Test R²=0.5914

[4/810] Running: LMPO2-L2-d4-rf0.1-seed256

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27657886: <gtn-abalone-lmpo2> in cluster <dcc> Exited

Job <gtn-abalone-lmpo2> was submitted from host <hpclogin1> by user <nicci> in cluster <dcc> at Tue Jan 20 13:20:19 2026
Job was executed on host(s) <8*n-62-20-4>, in queue <gpuv100>, as user <nicci> in cluster <dcc> at Tue Jan 20 13:20:20 2026
</zhome/6b/e/212868> was used as the home directory.
</zhome/6b/e/212868/GTN> was used as the working directory.
Started at Tue Jan 20 13:20:20 2026
Terminated at Tue Jan 20 13:23:06 2026
Results reported at Tue Jan 20 13:23:06 2026

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J gtn-abalone-lmpo2
#BSUB -W 12:00
#BSUB -n 8
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -R "rusage[mem=16GB]"
#BSUB -R "span[hosts=1]"
#BSUB -o logs/gtn-abalone-lmpo2_%J.out
#BSUB -e logs/gtn-abalone-lmpo2_%J.err
#BSUB -u nicci@dtu.dk

export HOME=/zhome/6b/e/212868

cd $HOME/GTN
source .venv/bin/activate

set -a
source $HOME/aim
set +a

python experiments/run_grid_search_gtn.py --config experiments/configs/uci_gtn_abalone_lmpo2.json --output-dir results/gtn_abalone_lmpo2

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   96.00 sec.
    Max Memory :                                 700 MB
    Average Memory :                             602.33 MB
    Total Requested Memory :                     131072.00 MB
    Delta Memory :                               130372.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   180 sec.
    Turnaround time :                            167 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/gtn-abalone-lmpo2_27657886.err> for stderr output of this job.

