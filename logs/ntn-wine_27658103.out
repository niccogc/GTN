======================================================================
EXPERIMENT PLAN SUMMARY
======================================================================
Total experiments: 240
Grid combinations: 48
Seeds per combination: 5

Parameter Grid:
  model: ['MPO2', 'MPO2TypeI', 'MMPO2', 'MMPO2TypeI'] (n=4)
  L: [3, 4] (n=2)
  bond_dim: [8, 12, 16] (n=3)
  jitter_start: [5.0, 0.1] (n=2)

Fixed Parameters:
  output_site: 1
  batch_size: 1024
  n_epochs: 15
  jitter_decay: 0.25
  adaptive_jitter: False
  patience: 4
  min_delta: 1e-06
  train_selection: True
  init_strength: 0.01
  rank: 5

Example runs (first 5):
  1. MPO2-L3-d8-jit5-seed42
  2. MPO2-L3-d8-jit5-seed7
  3. MPO2-L3-d8-jit5-seed123
  4. MPO2-L3-d8-jit5-seed256
  5. MPO2-L3-d8-jit5-seed999
  ... (235 more)

Loading dataset: wine...
  Dataset: wine
  Train: 124 samples
  Val: 27 samples
  Test: 27 samples
  Features: 13 (+1 bias = 13)
  Task: classification
  Device: cuda


[1/240] Running: MPO2-L3-d8-jit5-seed42
  AIM run started: fb77af13ac694255b37f0922
  AIM run finalized: fb77af13ac694255b37f0922
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j5_s42.json
  ✓ Test: Acc=0.8519 | Val: Acc=0.7778

[2/240] Running: MPO2-L3-d8-jit5-seed7
  AIM run started: 4fab1029cbe942e7a0773d41
  AIM run finalized: 4fab1029cbe942e7a0773d41
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j5_s7.json
  ✓ Test: Acc=0.6667 | Val: Acc=0.7407

[3/240] Running: MPO2-L3-d8-jit5-seed123
  AIM run started: d940101e7cb347e3a68d6ce0
  AIM run finalized: d940101e7cb347e3a68d6ce0
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j5_s123.json
  ✓ Test: Acc=0.7407 | Val: Acc=0.5926

[4/240] Running: MPO2-L3-d8-jit5-seed256
  AIM run started: 401d9c86ae3e404aa77759d8
  AIM run finalized: 401d9c86ae3e404aa77759d8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j5_s256.json
  ✓ Test: Acc=0.7037 | Val: Acc=0.5556

[5/240] Running: MPO2-L3-d8-jit5-seed999
  AIM run started: 4d1e1225e20d428eb49b7ab8
  AIM run finalized: 4d1e1225e20d428eb49b7ab8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j5_s999.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.7037

[6/240] Running: MPO2-L3-d8-jit0.1-seed42
  AIM run started: 96a45a2cacd74eeeb56cd7a4
  AIM run finalized: 96a45a2cacd74eeeb56cd7a4
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j0.1_s42.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.5185

[7/240] Running: MPO2-L3-d8-jit0.1-seed7
  AIM run started: 6caadff272d04750b4098134
  AIM run finalized: 6caadff272d04750b4098134
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j0.1_s7.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.6667

[8/240] Running: MPO2-L3-d8-jit0.1-seed123
  AIM run started: 83a4c6dd9ca54680a7c24312
  AIM run finalized: 83a4c6dd9ca54680a7c24312
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j0.1_s123.json
  ✓ Test: Acc=0.2222 | Val: Acc=0.2963

[9/240] Running: MPO2-L3-d8-jit0.1-seed256
  AIM run started: 5c96c0b7e41c449fabf70f37
  AIM run finalized: 5c96c0b7e41c449fabf70f37
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j0.1_s256.json
  ✓ Test: Acc=0.8889 | Val: Acc=0.6296

[10/240] Running: MPO2-L3-d8-jit0.1-seed999
  AIM run started: 2c49efda5a9f4340be0718a4
  AIM run finalized: 2c49efda5a9f4340be0718a4
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d8_j0.1_s999.json
  ✓ Test: Acc=0.6667 | Val: Acc=0.7778

[11/240] Running: MPO2-L3-d12-jit5-seed42
  AIM run started: b1a14b7a6802405ebe031a46
  AIM run finalized: b1a14b7a6802405ebe031a46
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j5_s42.json
  ✓ Test: Acc=0.5926 | Val: Acc=0.6667

[12/240] Running: MPO2-L3-d12-jit5-seed7
  AIM run started: d8522ca8e5514199b807f14d
  AIM run finalized: d8522ca8e5514199b807f14d
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j5_s7.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.7037

[13/240] Running: MPO2-L3-d12-jit5-seed123
  AIM run started: 875b154eb6634055812b1359
  AIM run finalized: 875b154eb6634055812b1359
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j5_s123.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.6296

[14/240] Running: MPO2-L3-d12-jit5-seed256
  AIM run started: 4092f98cd3f04331b88955c7
  AIM run finalized: 4092f98cd3f04331b88955c7
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j5_s256.json
  ✓ Test: Acc=0.5556 | Val: Acc=0.5926

[15/240] Running: MPO2-L3-d12-jit5-seed999
  AIM run started: 30dd694a60424d07971ec412
  AIM run finalized: 30dd694a60424d07971ec412
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j5_s999.json
  ✓ Test: Acc=0.6667 | Val: Acc=0.6667

[16/240] Running: MPO2-L3-d12-jit0.1-seed42
  AIM run started: 8fc0f2b3db6c4ed29cdcc7ef
  AIM run finalized: 8fc0f2b3db6c4ed29cdcc7ef
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j0.1_s42.json
  ✓ Test: Acc=0.7778 | Val: Acc=0.8148

[17/240] Running: MPO2-L3-d12-jit0.1-seed7
  AIM run started: 96e5c27834e3478caf17c4c9
  AIM run finalized: 96e5c27834e3478caf17c4c9
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j0.1_s7.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.7037

[18/240] Running: MPO2-L3-d12-jit0.1-seed123
  AIM run started: fdc99fd0149a4e56a13b030d
  AIM run finalized: fdc99fd0149a4e56a13b030d
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j0.1_s123.json
  ✓ Test: Acc=0.7778 | Val: Acc=0.7778

[19/240] Running: MPO2-L3-d12-jit0.1-seed256
  AIM run started: ec47b0fd3e5846b5a2753801
  AIM run finalized: ec47b0fd3e5846b5a2753801
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j0.1_s256.json
  ✓ Test: Acc=0.7407 | Val: Acc=0.6296

[20/240] Running: MPO2-L3-d12-jit0.1-seed999
  AIM run started: 0a7d2818e9a64925ba10bbd0
  AIM run finalized: 0a7d2818e9a64925ba10bbd0
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d12_j0.1_s999.json
  ✓ Test: Acc=0.6296 | Val: Acc=0.5926

[21/240] Running: MPO2-L3-d16-jit5-seed42
  AIM run started: d1a4c356810d44db8453d5c7
  AIM run finalized: d1a4c356810d44db8453d5c7
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j5_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 808.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[22/240] Running: MPO2-L3-d16-jit5-seed7
  AIM run started: 054d28bac07a4df0bf6bc97d
  AIM run finalized: 054d28bac07a4df0bf6bc97d
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j5_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[23/240] Running: MPO2-L3-d16-jit5-seed123
  AIM run started: 65dbeba38cd84811a07ffbfb
  AIM run finalized: 65dbeba38cd84811a07ffbfb
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j5_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[24/240] Running: MPO2-L3-d16-jit5-seed256
  AIM run started: e70415231a5c42238c53204c
  AIM run finalized: e70415231a5c42238c53204c
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j5_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[25/240] Running: MPO2-L3-d16-jit5-seed999
  AIM run started: d0093bef369b4bdb99ad76f6
  AIM run finalized: d0093bef369b4bdb99ad76f6
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j5_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[26/240] Running: MPO2-L3-d16-jit0.1-seed42
  AIM run started: 4771040c3ed6467e8fa5473f
  AIM run finalized: 4771040c3ed6467e8fa5473f
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j0.1_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[27/240] Running: MPO2-L3-d16-jit0.1-seed7
  AIM run started: 6273da5b8fcb4c4d8c62cad1
  AIM run finalized: 6273da5b8fcb4c4d8c62cad1
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j0.1_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[28/240] Running: MPO2-L3-d16-jit0.1-seed123
  AIM run started: 02ea17b44f7f48c59cde8478
  AIM run finalized: 02ea17b44f7f48c59cde8478
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j0.1_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[29/240] Running: MPO2-L3-d16-jit0.1-seed256
  AIM run started: 7890b4b8b89a4d43b07fc938
  AIM run finalized: 7890b4b8b89a4d43b07fc938
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j0.1_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[30/240] Running: MPO2-L3-d16-jit0.1-seed999
  AIM run started: 9c020e46e8d144179adb9a42
  AIM run finalized: 9c020e46e8d144179adb9a42
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L3_d16_j0.1_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 126.25 MiB is free. Including non-PyTorch memory, this process has 15.64 GiB memory in use. Of the allocated memory 14.44 GiB is allocated by PyTorch, and 812.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[31/240] Running: MPO2-L4-d8-jit5-seed42
  AIM run started: 18c301f1bfa642b5a3c771c0
  AIM run finalized: 18c301f1bfa642b5a3c771c0
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j5_s42.json
  ✓ Test: Acc=0.5926 | Val: Acc=0.5185

[32/240] Running: MPO2-L4-d8-jit5-seed7
  AIM run started: 70ef5e31d42546048acb758a
  AIM run finalized: 70ef5e31d42546048acb758a
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j5_s7.json
  ✓ Test: Acc=0.4074 | Val: Acc=0.3704

[33/240] Running: MPO2-L4-d8-jit5-seed123
  AIM run started: bb5217fa80fc435ba493ef0a
  AIM run finalized: bb5217fa80fc435ba493ef0a
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j5_s123.json
  ✓ Test: Acc=0.3333 | Val: Acc=0.2593

[34/240] Running: MPO2-L4-d8-jit5-seed256
  AIM run started: b5fb8377d739444db583610a
  AIM run finalized: b5fb8377d739444db583610a
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j5_s256.json
  ✓ Test: Acc=0.3704 | Val: Acc=0.4074

[35/240] Running: MPO2-L4-d8-jit5-seed999
  AIM run started: 45d59f8c640445c2b60b24d0
  AIM run finalized: 45d59f8c640445c2b60b24d0
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j5_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 10.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 163.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[36/240] Running: MPO2-L4-d8-jit0.1-seed42
  AIM run started: adcbb2e76400464999a13e31
  AIM run finalized: adcbb2e76400464999a13e31
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j0.1_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 12.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 88.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[37/240] Running: MPO2-L4-d8-jit0.1-seed7
  AIM run started: 0bc43d3e5e9e40e7ab773c22
  AIM run finalized: 0bc43d3e5e9e40e7ab773c22
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j0.1_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.24 GiB is allocated by PyTorch, and 106.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[38/240] Running: MPO2-L4-d8-jit0.1-seed123
  AIM run started: c600ee357ca945adb7d2f074
  AIM run finalized: c600ee357ca945adb7d2f074
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j0.1_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 98.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[39/240] Running: MPO2-L4-d8-jit0.1-seed256
  AIM run started: 981154617c2b47188083600b
  AIM run finalized: 981154617c2b47188083600b
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j0.1_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 98.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[40/240] Running: MPO2-L4-d8-jit0.1-seed999
  AIM run started: d7c4e8dae28e48e69127ef5b
  AIM run finalized: d7c4e8dae28e48e69127ef5b
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d8_j0.1_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 98.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[41/240] Running: MPO2-L4-d12-jit5-seed42
  AIM run started: e05e8d1d642b406eb7f94c86
  AIM run finalized: e05e8d1d642b406eb7f94c86
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j5_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[42/240] Running: MPO2-L4-d12-jit5-seed7
  AIM run started: 32eb1cfc2bad47fa80b2c106
  AIM run finalized: 32eb1cfc2bad47fa80b2c106
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j5_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[43/240] Running: MPO2-L4-d12-jit5-seed123
  AIM run started: 7fb05873b6084040b1dbde8b
  AIM run finalized: 7fb05873b6084040b1dbde8b
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j5_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[44/240] Running: MPO2-L4-d12-jit5-seed256
  AIM run started: ef6dc9f1918e4ad1a668dd47
  AIM run finalized: ef6dc9f1918e4ad1a668dd47
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j5_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[45/240] Running: MPO2-L4-d12-jit5-seed999
  AIM run started: d761e156e01b46b491b0cd03
  AIM run finalized: d761e156e01b46b491b0cd03
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j5_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[46/240] Running: MPO2-L4-d12-jit0.1-seed42
  AIM run started: 0d91c10ffb4a4a36bc2b6e13
  AIM run finalized: 0d91c10ffb4a4a36bc2b6e13
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j0.1_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[47/240] Running: MPO2-L4-d12-jit0.1-seed7
  AIM run started: 6e20761a12fd4899916bc8f8
  AIM run finalized: 6e20761a12fd4899916bc8f8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j0.1_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[48/240] Running: MPO2-L4-d12-jit0.1-seed123
  AIM run started: 42635c05ac7b45abbb2ccb76
  AIM run finalized: 42635c05ac7b45abbb2ccb76
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j0.1_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[49/240] Running: MPO2-L4-d12-jit0.1-seed256
  AIM run started: aae825aa7885455a9a455e12
  AIM run finalized: aae825aa7885455a9a455e12
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j0.1_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[50/240] Running: MPO2-L4-d12-jit0.1-seed999
  AIM run started: 15229f26a4de4090bb35927d
  AIM run finalized: 15229f26a4de4090bb35927d
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d12_j0.1_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 135.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[51/240] Running: MPO2-L4-d16-jit5-seed42
  AIM run started: 2c4ca1fa234047788ad2a9d0
  AIM run finalized: 2c4ca1fa234047788ad2a9d0
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j5_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[52/240] Running: MPO2-L4-d16-jit5-seed7
  AIM run started: 96e7e07e584444ae8544dea5
  AIM run finalized: 96e7e07e584444ae8544dea5
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j5_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[53/240] Running: MPO2-L4-d16-jit5-seed123
  AIM run started: 6eaf6ca53fdf400692c91912
  AIM run finalized: 6eaf6ca53fdf400692c91912
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j5_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[54/240] Running: MPO2-L4-d16-jit5-seed256
  AIM run started: b16ba67755be40229e235da8
  AIM run finalized: b16ba67755be40229e235da8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j5_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[55/240] Running: MPO2-L4-d16-jit5-seed999
  AIM run started: ae5fff78c30140e4b30bbbc8
  AIM run finalized: ae5fff78c30140e4b30bbbc8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j5_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[56/240] Running: MPO2-L4-d16-jit0.1-seed42
  AIM run started: ecedc09cde7f4612aba4446a
  AIM run finalized: ecedc09cde7f4612aba4446a
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j0.1_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[57/240] Running: MPO2-L4-d16-jit0.1-seed7
  AIM run started: 370cebe57f864edc88bd2518
  AIM run finalized: 370cebe57f864edc88bd2518
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j0.1_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[58/240] Running: MPO2-L4-d16-jit0.1-seed123
  AIM run started: fcf9b85d62314463994787dd
  AIM run finalized: fcf9b85d62314463994787dd
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j0.1_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[59/240] Running: MPO2-L4-d16-jit0.1-seed256
  AIM run started: d71084b2e79643e38d4eeeb8
  AIM run finalized: d71084b2e79643e38d4eeeb8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j0.1_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[60/240] Running: MPO2-L4-d16-jit0.1-seed999
  AIM run started: 497137240cf2485aa0c00c33
  AIM run finalized: 497137240cf2485aa0c00c33
  Experiment log saved to: experiment_logs/ntn_wine_MPO2_L4_d16_j0.1_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 762.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 14.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 87.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[61/240] Running: MPO2TypeI-L3-d8-jit5-seed42
  AIM run started: 01a6e2ce97e44d7fa07b6e90
  AIM run finalized: 01a6e2ce97e44d7fa07b6e90
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j5_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 8.25 MiB is free. Including non-PyTorch memory, this process has 15.75 GiB memory in use. Of the allocated memory 15.25 GiB is allocated by PyTorch, and 98.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[62/240] Running: MPO2TypeI-L3-d8-jit5-seed7
  AIM run started: 0acfa940bba84a558280f717
  AIM run finalized: 0acfa940bba84a558280f717
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j5_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 4.25 MiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 98.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[63/240] Running: MPO2TypeI-L3-d8-jit5-seed123
  AIM run started: 4e825c3609bc41c7bb6e8466
  AIM run finalized: 4e825c3609bc41c7bb6e8466
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j5_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.26 GiB is allocated by PyTorch, and 99.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[64/240] Running: MPO2TypeI-L3-d8-jit5-seed256
  AIM run started: 2af8e9fbf78b4ed58d7f7727
  AIM run finalized: 2af8e9fbf78b4ed58d7f7727
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j5_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 152.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[65/240] Running: MPO2TypeI-L3-d8-jit5-seed999
  AIM run started: 67f7647307cc4f6b84da7b19
  AIM run finalized: 67f7647307cc4f6b84da7b19
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j5_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 151.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[66/240] Running: MPO2TypeI-L3-d8-jit0.1-seed42
  AIM run started: 6e6d906862c5410088b7c0f8
  AIM run finalized: 6e6d906862c5410088b7c0f8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j0.1_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 151.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[67/240] Running: MPO2TypeI-L3-d8-jit0.1-seed7
  AIM run started: f267a56ce5bb4979bf6e3a6a
  AIM run finalized: f267a56ce5bb4979bf6e3a6a
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j0.1_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 151.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[68/240] Running: MPO2TypeI-L3-d8-jit0.1-seed123
  AIM run started: edb95afef192486b978534a4
  AIM run finalized: edb95afef192486b978534a4
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j0.1_s123.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 151.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[69/240] Running: MPO2TypeI-L3-d8-jit0.1-seed256
  AIM run started: aaa68d6047414f14bf218004
  AIM run finalized: aaa68d6047414f14bf218004
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j0.1_s256.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 151.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[70/240] Running: MPO2TypeI-L3-d8-jit0.1-seed999
  AIM run started: 5dc2a87754e14b12baa5e624
  AIM run finalized: 5dc2a87754e14b12baa5e624
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d8_j0.1_s999.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 152.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[71/240] Running: MPO2TypeI-L3-d12-jit5-seed42
  AIM run started: 9e01e1ea1f4843ec83acd899
  AIM run finalized: 9e01e1ea1f4843ec83acd899
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d12_j5_s42.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 152.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[72/240] Running: MPO2TypeI-L3-d12-jit5-seed7
  AIM run started: db1f64fc7391407ba3a01bb8
  AIM run finalized: db1f64fc7391407ba3a01bb8
  Experiment log saved to: experiment_logs/ntn_wine_MPO2TypeI_L3_d12_j5_s7.json
  ✗ FAILED: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.77 GiB of which 256.00 KiB is free. Including non-PyTorch memory, this process has 15.76 GiB memory in use. Of the allocated memory 15.21 GiB is allocated by PyTorch, and 152.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[73/240] Running: MPO2TypeI-L3-d12-jit5-seed123

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27658103: <ntn-wine> in cluster <dcc> Exited

Job <ntn-wine> was submitted from host <hpclogin1> by user <nicci> in cluster <dcc> at Tue Jan 20 13:27:44 2026
Job was executed on host(s) <8*n-62-20-6>, in queue <gpuv100>, as user <nicci> in cluster <dcc> at Wed Jan 21 17:26:23 2026
</zhome/6b/e/212868> was used as the home directory.
</zhome/6b/e/212868/GTN> was used as the working directory.
Started at Wed Jan 21 17:26:23 2026
Terminated at Wed Jan 21 17:33:15 2026
Results reported at Wed Jan 21 17:33:15 2026

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J ntn-wine
#BSUB -W 3:00
#BSUB -n 8
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -R "rusage[mem=16GB]"
#BSUB -R "span[hosts=1]"
#BSUB -o logs/ntn-wine_%J.out
#BSUB -e logs/ntn-wine_%J.err
#BSUB -u nicci@dtu.dk

export HOME=/zhome/6b/e/212868

cd $HOME/GTN
source .venv/bin/activate

set -a
source $HOME/aim
set +a

python experiments/run_grid_search.py --config experiments/configs/uci_ntn_wine.json 

------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   62.04 sec.
    Max Memory :                                 779 MB
    Average Memory :                             710.40 MB
    Total Requested Memory :                     131072.00 MB
    Delta Memory :                               130293.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   415 sec.
    Turnaround time :                            101131 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ntn-wine_27658103.err> for stderr output of this job.

