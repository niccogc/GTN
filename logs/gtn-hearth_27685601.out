
Loading dataset: hearth
  Task: classification
  Train: 212 samples
  Val: 45 samples
  Test: 46 samples
  Input dim: 11
  Output dim: 5
  Device: cuda
======================================================================
EXPERIMENT PLAN SUMMARY
======================================================================
Total experiments: 360
Grid combinations: 72
Seeds per combination: 5

Parameter Grid:
  model: ['MPO2', 'MPO2TypeI_GTN', 'MMPO2', 'MMPO2TypeI_GTN'] (n=4)
  L: [3, 4] (n=2)
  bond_dim: [8, 12, 16] (n=3)
  lr: [0.01, 0.001, 0.0001] (n=3)

Fixed Parameters:
  output_site: 1
  batch_size: 64
  n_epochs: 1000
  patience: 40
  min_delta: 1e-08
  optimizer: adamw
  init_strength: 0.01
  rank: 5

Example runs (first 5):
  1. MPO2-L3-d8-seed42
  2. MPO2-L3-d8-seed7
  3. MPO2-L3-d8-seed123
  4. MPO2-L3-d8-seed256
  5. MPO2-L3-d8-seed999
  ... (355 more)

[271/360] MMPO2TypeI_GTN-L3-d8-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[271/360] Running: MMPO2TypeI_GTN-L3-d8-seed42
  AIM run started: 186fb6ace7514ec789b4e57b
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[272/360] MMPO2TypeI_GTN-L3-d8-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[272/360] Running: MMPO2TypeI_GTN-L3-d8-seed7
  AIM run started: b930b17d58834d72bebfb386
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[273/360] MMPO2TypeI_GTN-L3-d8-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[273/360] Running: MMPO2TypeI_GTN-L3-d8-seed123
  AIM run started: d6901fc3d0534b2fb15beefc
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[274/360] MMPO2TypeI_GTN-L3-d8-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[274/360] Running: MMPO2TypeI_GTN-L3-d8-seed256
  AIM run started: ee4d093d652a4341ab73fb75
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[275/360] MMPO2TypeI_GTN-L3-d8-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[275/360] Running: MMPO2TypeI_GTN-L3-d8-seed999
  AIM run started: 12b1486fe7cb420c95184224
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[276/360] MMPO2TypeI_GTN-L3-d8-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[276/360] Running: MMPO2TypeI_GTN-L3-d8-seed42
  AIM run started: accdaee18ce746e4ba9e4fd2
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[277/360] MMPO2TypeI_GTN-L3-d8-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[277/360] Running: MMPO2TypeI_GTN-L3-d8-seed7
  AIM run started: a780e7c1dcd5441f97ac23a3
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[278/360] MMPO2TypeI_GTN-L3-d8-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[278/360] Running: MMPO2TypeI_GTN-L3-d8-seed123
  AIM run started: 317c42cabfc843558514ba82
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[279/360] MMPO2TypeI_GTN-L3-d8-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[279/360] Running: MMPO2TypeI_GTN-L3-d8-seed256
  AIM run started: e6b7067fb7fb4c2d92c6ece8
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[280/360] MMPO2TypeI_GTN-L3-d8-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[280/360] Running: MMPO2TypeI_GTN-L3-d8-seed999
  AIM run started: cae94a82f2b34ac1add37183
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[281/360] MMPO2TypeI_GTN-L3-d8-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[281/360] Running: MMPO2TypeI_GTN-L3-d8-seed42
  AIM run started: 5f8336e538cc49a09f9dba41
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[282/360] MMPO2TypeI_GTN-L3-d8-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[282/360] Running: MMPO2TypeI_GTN-L3-d8-seed7
  AIM run started: 4409c893ab5d437c9fac5243
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[283/360] MMPO2TypeI_GTN-L3-d8-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[283/360] Running: MMPO2TypeI_GTN-L3-d8-seed123
  AIM run started: 056f507159b146dabc361376
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[284/360] MMPO2TypeI_GTN-L3-d8-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[284/360] Running: MMPO2TypeI_GTN-L3-d8-seed256
  AIM run started: eff7b05ede8a44d6a7b9ed2b
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[285/360] MMPO2TypeI_GTN-L3-d8-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[285/360] Running: MMPO2TypeI_GTN-L3-d8-seed999
  AIM run started: f453a6c22e584a9393b09bd0
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[286/360] MMPO2TypeI_GTN-L3-d12-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[286/360] Running: MMPO2TypeI_GTN-L3-d12-seed42
  AIM run started: 2ceca10c600543dea17ce0c8
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[287/360] MMPO2TypeI_GTN-L3-d12-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[287/360] Running: MMPO2TypeI_GTN-L3-d12-seed7
  AIM run started: 610a83c07d474790baf9a139
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[288/360] MMPO2TypeI_GTN-L3-d12-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[288/360] Running: MMPO2TypeI_GTN-L3-d12-seed123
  AIM run started: 90d628ecf4bd477fa1a48286
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[289/360] MMPO2TypeI_GTN-L3-d12-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[289/360] Running: MMPO2TypeI_GTN-L3-d12-seed256
  AIM run started: be645ca85320443b95922db1
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[290/360] MMPO2TypeI_GTN-L3-d12-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[290/360] Running: MMPO2TypeI_GTN-L3-d12-seed999
  AIM run started: fb5fb6ada63b4150a5507526
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[291/360] MMPO2TypeI_GTN-L3-d12-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[291/360] Running: MMPO2TypeI_GTN-L3-d12-seed42
  AIM run started: 0aec9c5f36dd4c1d94897361
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[292/360] MMPO2TypeI_GTN-L3-d12-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[292/360] Running: MMPO2TypeI_GTN-L3-d12-seed7
  AIM run started: be1bc39f12f845a8995c2575
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[293/360] MMPO2TypeI_GTN-L3-d12-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[293/360] Running: MMPO2TypeI_GTN-L3-d12-seed123
  AIM run started: e788059dab654215946de311
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[294/360] MMPO2TypeI_GTN-L3-d12-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[294/360] Running: MMPO2TypeI_GTN-L3-d12-seed256
  AIM run started: e633ccb87f05475ea75fa5cd
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[295/360] MMPO2TypeI_GTN-L3-d12-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[295/360] Running: MMPO2TypeI_GTN-L3-d12-seed999
  AIM run started: 3e23cf05d771494fb6a0f64d
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[296/360] MMPO2TypeI_GTN-L3-d12-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[296/360] Running: MMPO2TypeI_GTN-L3-d12-seed42
  AIM run started: d9267c5adaf04b26b2de886f
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[297/360] MMPO2TypeI_GTN-L3-d12-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[297/360] Running: MMPO2TypeI_GTN-L3-d12-seed7
  AIM run started: 79e4c192f3344e52b30cb9de
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[298/360] MMPO2TypeI_GTN-L3-d12-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[298/360] Running: MMPO2TypeI_GTN-L3-d12-seed123
  AIM run started: 37d2e39571cc42969c8f442f
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[299/360] MMPO2TypeI_GTN-L3-d12-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[299/360] Running: MMPO2TypeI_GTN-L3-d12-seed256
  AIM run started: 948b27babace40a1967a7d52
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[300/360] MMPO2TypeI_GTN-L3-d12-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[300/360] Running: MMPO2TypeI_GTN-L3-d12-seed999
  AIM run started: c052a30a21bb46daa8076fa1
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[301/360] MMPO2TypeI_GTN-L3-d16-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[301/360] Running: MMPO2TypeI_GTN-L3-d16-seed42
  AIM run started: f3317af428a848e9a829d431
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[302/360] MMPO2TypeI_GTN-L3-d16-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[302/360] Running: MMPO2TypeI_GTN-L3-d16-seed7
  AIM run started: 309cc0d5400c488bb06609c7
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[303/360] MMPO2TypeI_GTN-L3-d16-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[303/360] Running: MMPO2TypeI_GTN-L3-d16-seed123
  AIM run started: 98c7f260e990436d931a8e5d
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[304/360] MMPO2TypeI_GTN-L3-d16-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[304/360] Running: MMPO2TypeI_GTN-L3-d16-seed256
  AIM run started: 6fe79ab8271b4fac89e89f3d
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[305/360] MMPO2TypeI_GTN-L3-d16-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[305/360] Running: MMPO2TypeI_GTN-L3-d16-seed999
  AIM run started: 784e411c85104ff9aec3c5ce
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[306/360] MMPO2TypeI_GTN-L3-d16-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[306/360] Running: MMPO2TypeI_GTN-L3-d16-seed42
  AIM run started: e3e486e0e7ce4be6ae274ec0
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[307/360] MMPO2TypeI_GTN-L3-d16-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[307/360] Running: MMPO2TypeI_GTN-L3-d16-seed7
  AIM run started: acf1ae71882b420dac727332
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[308/360] MMPO2TypeI_GTN-L3-d16-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[308/360] Running: MMPO2TypeI_GTN-L3-d16-seed123
  AIM run started: db0c5219183d4e558c770e3b
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[309/360] MMPO2TypeI_GTN-L3-d16-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[309/360] Running: MMPO2TypeI_GTN-L3-d16-seed256
  AIM run started: 138656adc2b247e99fa02c86
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[310/360] MMPO2TypeI_GTN-L3-d16-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[310/360] Running: MMPO2TypeI_GTN-L3-d16-seed999
  AIM run started: 3815608f0bea4a1b9550a204
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[311/360] MMPO2TypeI_GTN-L3-d16-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[311/360] Running: MMPO2TypeI_GTN-L3-d16-seed42
  AIM run started: ff3caa2a8e3f45b78c84da34
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[312/360] MMPO2TypeI_GTN-L3-d16-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[312/360] Running: MMPO2TypeI_GTN-L3-d16-seed7
  AIM run started: 8e7f3c0339a24a49a15387d7
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[313/360] MMPO2TypeI_GTN-L3-d16-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[313/360] Running: MMPO2TypeI_GTN-L3-d16-seed123
  AIM run started: 4d3d31156e4746cfac11ce97
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[314/360] MMPO2TypeI_GTN-L3-d16-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[314/360] Running: MMPO2TypeI_GTN-L3-d16-seed256
  AIM run started: ce8868cf8b6f45ff8a93ec4e
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[315/360] MMPO2TypeI_GTN-L3-d16-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[315/360] Running: MMPO2TypeI_GTN-L3-d16-seed999
  AIM run started: ffaf565c4f7b4a15a540d5a1
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[316/360] MMPO2TypeI_GTN-L4-d8-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[316/360] Running: MMPO2TypeI_GTN-L4-d8-seed42
  AIM run started: 4a59300eb62b481cbc8652c2
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[317/360] MMPO2TypeI_GTN-L4-d8-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[317/360] Running: MMPO2TypeI_GTN-L4-d8-seed7
  AIM run started: c96d5f609fc64cfcbedaef36
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[318/360] MMPO2TypeI_GTN-L4-d8-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[318/360] Running: MMPO2TypeI_GTN-L4-d8-seed123
  AIM run started: b482f6dde0ac4ec08f55e940
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[319/360] MMPO2TypeI_GTN-L4-d8-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[319/360] Running: MMPO2TypeI_GTN-L4-d8-seed256
  AIM run started: 10a0822d224746ac95c6e16d
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[320/360] MMPO2TypeI_GTN-L4-d8-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[320/360] Running: MMPO2TypeI_GTN-L4-d8-seed999
  AIM run started: 31e9551513fc45e8ae9c939c
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[321/360] MMPO2TypeI_GTN-L4-d8-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[321/360] Running: MMPO2TypeI_GTN-L4-d8-seed42
  AIM run started: de09cf8f3b394c3c86598c22
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[322/360] MMPO2TypeI_GTN-L4-d8-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[322/360] Running: MMPO2TypeI_GTN-L4-d8-seed7
  AIM run started: f1df910b16614c67a5a87ccf
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[323/360] MMPO2TypeI_GTN-L4-d8-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[323/360] Running: MMPO2TypeI_GTN-L4-d8-seed123
  AIM run started: aa113e488d504800944201b1
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[324/360] MMPO2TypeI_GTN-L4-d8-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[324/360] Running: MMPO2TypeI_GTN-L4-d8-seed256
  AIM run started: 434bb01809d54526bee1eec0
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[325/360] MMPO2TypeI_GTN-L4-d8-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[325/360] Running: MMPO2TypeI_GTN-L4-d8-seed999
  AIM run started: 9daca95ae9f6460fb88e8b8a
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[326/360] MMPO2TypeI_GTN-L4-d8-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[326/360] Running: MMPO2TypeI_GTN-L4-d8-seed42
  AIM run started: a0628b90ae9f40779fee296f
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[327/360] MMPO2TypeI_GTN-L4-d8-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[327/360] Running: MMPO2TypeI_GTN-L4-d8-seed7
  AIM run started: 144a1ed62b4945bbb9321ab9
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[328/360] MMPO2TypeI_GTN-L4-d8-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[328/360] Running: MMPO2TypeI_GTN-L4-d8-seed123
  AIM run started: 4b730968f94f4841a57382e5
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[329/360] MMPO2TypeI_GTN-L4-d8-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[329/360] Running: MMPO2TypeI_GTN-L4-d8-seed256
  AIM run started: 6ac7fab6ea5c48b68aaa1aae
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[330/360] MMPO2TypeI_GTN-L4-d8-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[330/360] Running: MMPO2TypeI_GTN-L4-d8-seed999
  AIM run started: 0d1af3d0d936491fbbbd6215
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[331/360] MMPO2TypeI_GTN-L4-d12-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[331/360] Running: MMPO2TypeI_GTN-L4-d12-seed42
  AIM run started: a2222b4b7f274b70b67ae390
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[332/360] MMPO2TypeI_GTN-L4-d12-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[332/360] Running: MMPO2TypeI_GTN-L4-d12-seed7
  AIM run started: 46fbfa8f9c41435db62d00be
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[333/360] MMPO2TypeI_GTN-L4-d12-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[333/360] Running: MMPO2TypeI_GTN-L4-d12-seed123
  AIM run started: ff5bbd99f8144cc2b41209ce
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[334/360] MMPO2TypeI_GTN-L4-d12-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[334/360] Running: MMPO2TypeI_GTN-L4-d12-seed256
  AIM run started: decc092a5e034f7f85e43952
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[335/360] MMPO2TypeI_GTN-L4-d12-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[335/360] Running: MMPO2TypeI_GTN-L4-d12-seed999
  AIM run started: aa48226507774a528af4c629
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[336/360] MMPO2TypeI_GTN-L4-d12-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[336/360] Running: MMPO2TypeI_GTN-L4-d12-seed42
  AIM run started: 5858ab66539849f1bae21b89
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[337/360] MMPO2TypeI_GTN-L4-d12-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[337/360] Running: MMPO2TypeI_GTN-L4-d12-seed7
  AIM run started: 754ea06a6c3540f98f7c831c
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[338/360] MMPO2TypeI_GTN-L4-d12-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[338/360] Running: MMPO2TypeI_GTN-L4-d12-seed123
  AIM run started: a1faa6fa73be40678084cc78
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[339/360] MMPO2TypeI_GTN-L4-d12-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[339/360] Running: MMPO2TypeI_GTN-L4-d12-seed256
  AIM run started: c4701ac294394994a67d04c5
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[340/360] MMPO2TypeI_GTN-L4-d12-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[340/360] Running: MMPO2TypeI_GTN-L4-d12-seed999
  AIM run started: 94a5a66b08f84b37b46b0380
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[341/360] MMPO2TypeI_GTN-L4-d12-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[341/360] Running: MMPO2TypeI_GTN-L4-d12-seed42
  AIM run started: f425d3b5e4854cb49bb78e1f
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[342/360] MMPO2TypeI_GTN-L4-d12-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[342/360] Running: MMPO2TypeI_GTN-L4-d12-seed7
  AIM run started: 9d42240d035e4ff892eaa8ec
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[343/360] MMPO2TypeI_GTN-L4-d12-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[343/360] Running: MMPO2TypeI_GTN-L4-d12-seed123
  AIM run started: d27941711c3e45f490948b02
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[344/360] MMPO2TypeI_GTN-L4-d12-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[344/360] Running: MMPO2TypeI_GTN-L4-d12-seed256
  AIM run started: fba2f0037fc8412b8793e399
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[345/360] MMPO2TypeI_GTN-L4-d12-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[345/360] Running: MMPO2TypeI_GTN-L4-d12-seed999
  AIM run started: 1d1a02b59ec24dfb84e71c66
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[346/360] MMPO2TypeI_GTN-L4-d16-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[346/360] Running: MMPO2TypeI_GTN-L4-d16-seed42
  AIM run started: 05746e2b167744f0bf01da81
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[347/360] MMPO2TypeI_GTN-L4-d16-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[347/360] Running: MMPO2TypeI_GTN-L4-d16-seed7
  AIM run started: c5100180acb74fa193bb2375
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[348/360] MMPO2TypeI_GTN-L4-d16-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[348/360] Running: MMPO2TypeI_GTN-L4-d16-seed123
  AIM run started: 4d662c54637747b995bedc05
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[349/360] MMPO2TypeI_GTN-L4-d16-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[349/360] Running: MMPO2TypeI_GTN-L4-d16-seed256
  AIM run started: 4af3409e5e5d45e9b4718ccd
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[350/360] MMPO2TypeI_GTN-L4-d16-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[350/360] Running: MMPO2TypeI_GTN-L4-d16-seed999
  AIM run started: 9b8bc50dd6254e21920c4e47
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[351/360] MMPO2TypeI_GTN-L4-d16-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[351/360] Running: MMPO2TypeI_GTN-L4-d16-seed42
  AIM run started: b8c4e2a505a5492081855570
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[352/360] MMPO2TypeI_GTN-L4-d16-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[352/360] Running: MMPO2TypeI_GTN-L4-d16-seed7
  AIM run started: 9c7cadb88af04f49a9286c81
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[353/360] MMPO2TypeI_GTN-L4-d16-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[353/360] Running: MMPO2TypeI_GTN-L4-d16-seed123
  AIM run started: f07234f5f5704e7b88d61db0
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[354/360] MMPO2TypeI_GTN-L4-d16-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[354/360] Running: MMPO2TypeI_GTN-L4-d16-seed256
  AIM run started: edbf518bf9dd43559a5c8e54
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[355/360] MMPO2TypeI_GTN-L4-d16-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[355/360] Running: MMPO2TypeI_GTN-L4-d16-seed999
  AIM run started: dc83efa6bba340bea981b923
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[356/360] MMPO2TypeI_GTN-L4-d16-seed42 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[356/360] Running: MMPO2TypeI_GTN-L4-d16-seed42
  AIM run started: da2ab394244649c99785b1b9
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[357/360] MMPO2TypeI_GTN-L4-d16-seed7 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[357/360] Running: MMPO2TypeI_GTN-L4-d16-seed7
  AIM run started: 04c9312be6ef4af4a2c2ab4f
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[358/360] MMPO2TypeI_GTN-L4-d16-seed123 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[358/360] Running: MMPO2TypeI_GTN-L4-d16-seed123
  AIM run started: 478f8f50665e4058a0ccd976
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[359/360] MMPO2TypeI_GTN-L4-d16-seed256 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[359/360] Running: MMPO2TypeI_GTN-L4-d16-seed256
  AIM run started: c3b981c385074147bb21d62e
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)
[360/360] MMPO2TypeI_GTN-L4-d16-seed999 - RETRYING (Expected all tensors to be on the same device, but got mat2 is on cuda:0, differ...)

[360/360] Running: MMPO2TypeI_GTN-L4-d16-seed999
  AIM run started: 7b78b8a797b14ffeaf7e3f20
  ✗ FAILED: Expected all tensors to be on the same device, but got mat2 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_mm)

======================================================================
GRID SEARCH SUMMARY
======================================================================
Total runs: 360
Completed: 0
Skipped: 270
Failed: 90
Time: 962.1s (2.7s per run)
Grid search complete. Marked as .complete
======================================================================

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27685601: <gtn-hearth> in cluster <dcc> Done

Job <gtn-hearth> was submitted from host <hpclogin1> by user <nicci> in cluster <dcc> at Sun Jan 25 14:07:49 2026
Job was executed on host(s) <8*n-62-11-13>, in queue <gpuv100>, as user <nicci> in cluster <dcc> at Sun Jan 25 15:47:27 2026
</zhome/6b/e/212868> was used as the home directory.
</zhome/6b/e/212868/GTN> was used as the working directory.
Started at Sun Jan 25 15:47:27 2026
Terminated at Sun Jan 25 16:03:51 2026
Results reported at Sun Jan 25 16:03:51 2026

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J gtn-hearth
#BSUB -W 12:00
#BSUB -n 8
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -R "rusage[mem=16GB]"
#BSUB -R "span[hosts=1]"
#BSUB -o logs/gtn-hearth_%J.out
#BSUB -e logs/gtn-hearth_%J.err
#BSUB -u nicci@dtu.dk

export HOME=/zhome/6b/e/212868

cd $HOME/GTN
source .venv/bin/activate

set -a
source $HOME/aim
set +a

python experiments/run_grid_search_gtn.py --config experiments/configs/uci_gtn_hearth.json --output-dir results/gtn_hearth

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   103.29 sec.
    Max Memory :                                 561 MB
    Average Memory :                             548.78 MB
    Total Requested Memory :                     131072.00 MB
    Delta Memory :                               130511.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   985 sec.
    Turnaround time :                            6962 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/gtn-hearth_27685601.err> for stderr output of this job.

