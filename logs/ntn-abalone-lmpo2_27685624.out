======================================================================
EXPERIMENT PLAN SUMMARY
======================================================================
Total experiments: 360
Grid combinations: 72
Seeds per combination: 5

Parameter Grid:
  model: ['LMPO2', 'LMPO2TypeI'] (n=2)
  L: [3, 4] (n=2)
  bond_dim: [8, 12, 16] (n=3)
  jitter_start: [5.0, 0.1] (n=2)
  reduction_factor: [0.1, 0.3, 0.5] (n=3)

Fixed Parameters:
  output_site: 1
  batch_size: 1024
  n_epochs: 15
  jitter_decay: 0.25
  adaptive_jitter: False
  patience: 4
  min_delta: 1e-06
  train_selection: True
  init_strength: 0.01
  rank: 5

Example runs (first 5):
  1. LMPO2-L3-d8-jit5-rf0.1-seed42
  2. LMPO2-L3-d8-jit5-rf0.1-seed7
  3. LMPO2-L3-d8-jit5-rf0.1-seed123
  4. LMPO2-L3-d8-jit5-rf0.1-seed256
  5. LMPO2-L3-d8-jit5-rf0.1-seed999
  ... (355 more)

Loading dataset: abalone...
  Dataset: abalone
  Train: 2923 samples
  Val: 627 samples
  Test: 627 samples
  Features: 11 (+1 bias = 11)
  Task: regression
  Device: cuda


[3/360] Running: LMPO2-L3-d8-jit5-rf0.1-seed123
  AIM run started: 824f574198f44a6daf68bcdb
  AIM run finalized: 824f574198f44a6daf68bcdb
  Experiment log saved to: experiment_logs/ntn_abalone_lmpo2_LMPO2_L3_d8_j5_s123.json
  ✓ Test: R²=0.5932 | Val: R²=0.5174

[4/360] Running: LMPO2-L3-d8-jit5-rf0.1-seed256
  AIM run started: 6b549632483d49eaaecd203a
  AIM run finalized: 6b549632483d49eaaecd203a
  Experiment log saved to: experiment_logs/ntn_abalone_lmpo2_LMPO2_L3_d8_j5_s256.json
  ✓ Test: R²=0.4810 | Val: R²=0.5308

[5/360] Running: LMPO2-L3-d8-jit5-rf0.1-seed999
  AIM run started: b6bb4bba47a443e4972fb9f8

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 27685624: <ntn-abalone-lmpo2> in cluster <dcc> Exited

Job <ntn-abalone-lmpo2> was submitted from host <hpclogin1> by user <nicci> in cluster <dcc> at Sun Jan 25 14:07:58 2026
Job was executed on host(s) <8*n-62-20-11>, in queue <gpuv100>, as user <nicci> in cluster <dcc> at Sun Jan 25 19:34:09 2026
</zhome/6b/e/212868> was used as the home directory.
</zhome/6b/e/212868/GTN> was used as the working directory.
Started at Sun Jan 25 19:34:09 2026
Terminated at Sun Jan 25 19:34:56 2026
Results reported at Sun Jan 25 19:34:56 2026

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -J ntn-abalone-lmpo2
#BSUB -W 12:00
#BSUB -n 8
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -R "rusage[mem=32GB]"
#BSUB -R "span[hosts=1]"
#BSUB -o logs/ntn-abalone-lmpo2_%J.out
#BSUB -e logs/ntn-abalone-lmpo2_%J.err
#BSUB -u nicci@dtu.dk

export HOME=/zhome/6b/e/212868

cd $HOME/GTN
source .venv/bin/activate

set -a
source $HOME/aim
set +a

python experiments/run_grid_search.py --config experiments/configs/uci_ntn_abalone_lmpo2.json 

------------------------------------------------------------

Exited with exit code 137.

Resource usage summary:

    CPU time :                                   14.00 sec.
    Max Memory :                                 444 MB
    Average Memory :                             431.67 MB
    Total Requested Memory :                     262144.00 MB
    Delta Memory :                               261700.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   46 sec.
    Turnaround time :                            19618 sec.

The output (if any) is above this job summary.



PS:

Read file <logs/ntn-abalone-lmpo2_27685624.err> for stderr output of this job.

