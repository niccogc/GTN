Loading abalone dataset...
Dataset: 2923 train, 627 val, 627 test
Input dim: 11, Output dim: 1
Creating model: MPO2 with L=2, bond_dim=8
Starting training for 1000 epochs with early stopping (patience=40, min_delta=1e-08)...
Epoch   1: Train Loss=1786.6615, Val Loss=946.2376, Val R²=-93.3135
Epoch  51: Train Loss=54.4652, Val Loss=42.7834, Val R²=-3.2643
Epoch 101: Train Loss=15.1387, Val Loss=14.9618, Val R²=-0.4913
Epoch 151: Train Loss=8.3748, Val Loss=8.1288, Val R²=0.1898
Epoch 201: Train Loss=6.2976, Val Loss=6.4951, Val R²=0.3526
Epoch 251: Train Loss=5.4124, Val Loss=5.8151, Val R²=0.4204
Epoch 301: Train Loss=5.0000, Val Loss=5.4593, Val R²=0.4559
Epoch 351: Train Loss=4.8036, Val Loss=5.1952, Val R²=0.4822
Epoch 401: Train Loss=4.7285, Val Loss=5.2977, Val R²=0.4720
Epoch 451: Train Loss=5.2212, Val Loss=4.9944, Val R²=0.5022
Epoch 501: Train Loss=4.5226, Val Loss=5.0854, Val R²=0.4931
Epoch 551: Train Loss=4.5249, Val Loss=4.9170, Val R²=0.5099
Epoch 601: Train Loss=4.4180, Val Loss=4.9317, Val R²=0.5084
Epoch 651: Train Loss=4.5754, Val Loss=4.8428, Val R²=0.5173
Epoch 701: Train Loss=4.3593, Val Loss=4.7993, Val R²=0.5216
Epoch 751: Train Loss=4.3487, Val Loss=4.8155, Val R²=0.5200
Epoch 801: Train Loss=4.3497, Val Loss=4.7679, Val R²=0.5248
Epoch 851: Train Loss=4.3281, Val Loss=4.7720, Val R²=0.5244

⏸ Early stopping triggered at epoch 875
  No improvement > 1e-08 for 40 epochs
  Best Val R²: 0.528856

Final results:
.4f
.4f
.4f
Stopped early: True
Early stopping epoch: 875

Plot saved as: test_plots/abalone_gtn_progression_L2_early_stopping.png
